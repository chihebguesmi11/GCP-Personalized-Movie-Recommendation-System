{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Save Model\n",
    "## Ramy - Model Training\n",
    "\n",
    "This notebook trains the final model and saves it for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T21:38:51.533388Z",
     "iopub.status.busy": "2025-11-29T21:38:51.532990Z",
     "iopub.status.idle": "2025-11-29T21:38:52.214145Z",
     "shell.execute_reply": "2025-11-29T21:38:52.211349Z",
     "shell.execute_reply.started": "2025-11-29T21:38:51.533352Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "Training session: 2025-11-29 21:38:52\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"Training session: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T21:39:58.500675Z",
     "iopub.status.busy": "2025-11-29T21:39:58.500041Z",
     "iopub.status.idle": "2025-11-29T21:39:58.535609Z",
     "shell.execute_reply": "2025-11-29T21:39:58.534100Z",
     "shell.execute_reply.started": "2025-11-29T21:39:58.500634Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MovieRecommender class created!\n"
     ]
    }
   ],
   "source": [
    "# Create the production-ready MovieRecommender class\n",
    "\n",
    "class MovieRecommender:\n",
    "    \"\"\"\n",
    "    Production-ready Movie Recommendation System\n",
    "    Uses Item-Based Collaborative Filtering with Cosine Similarity\n",
    "    \n",
    "    Attributes:\n",
    "        user_item_matrix: Pivot table of user ratings\n",
    "        item_similarity_df: Item-item similarity matrix\n",
    "        movies_df: Movie metadata (titles, genres)\n",
    "        is_trained: Boolean flag indicating if model is trained\n",
    "        training_info: Dictionary with training metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the recommender system\"\"\"\n",
    "        self.user_item_matrix = None\n",
    "        self.item_similarity_df = None\n",
    "        self.movies_df = None\n",
    "        self.is_trained = False\n",
    "        self.training_info = {\n",
    "            'trained_at': None,\n",
    "            'num_users': 0,\n",
    "            'num_movies': 0,\n",
    "            'num_ratings': 0,\n",
    "            'sparsity': 0.0,\n",
    "            'model_version': '1.0'\n",
    "        }\n",
    "        print(\"üé¨ MovieRecommender initialized\")\n",
    "    \n",
    "    def train(self, ratings_df, movies_df, verbose=True):\n",
    "        \"\"\"\n",
    "        Train the recommendation model\n",
    "        \n",
    "        Args:\n",
    "            ratings_df (DataFrame): User ratings with columns [userId, movieId, rating]\n",
    "            movies_df (DataFrame): Movie metadata with columns [movieId, title, genres]\n",
    "            verbose (bool): Print training progress\n",
    "            \n",
    "        Returns:\n",
    "            dict: Training statistics\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"=\" * 80)\n",
    "            print(\"TRAINING MOVIE RECOMMENDER\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "        # Store movie metadata\n",
    "        self.movies_df = movies_df.copy()\n",
    "        \n",
    "        # Remove duplicates\n",
    "        ratings_df = ratings_df.drop_duplicates(['userId', 'movieId'], keep='last')\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nüìä Training data:\")\n",
    "            print(f\"  ‚Ä¢ Users: {ratings_df['userId'].nunique():,}\")\n",
    "            print(f\"  ‚Ä¢ Movies: {ratings_df['movieId'].nunique():,}\")\n",
    "            print(f\"  ‚Ä¢ Ratings: {len(ratings_df):,}\")\n",
    "            print(f\"  ‚Ä¢ Average rating: {ratings_df['rating'].mean():.2f}\")\n",
    "        \n",
    "        # Create user-item matrix\n",
    "        if verbose:\n",
    "            print(\"\\n‚è≥ Creating user-item matrix...\")\n",
    "        \n",
    "        self.user_item_matrix = ratings_df.pivot_table(\n",
    "            index='userId',\n",
    "            columns='movieId',\n",
    "            values='rating',\n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        # Calculate sparsity\n",
    "        num_ratings = (self.user_item_matrix > 0).sum().sum()\n",
    "        total_cells = self.user_item_matrix.shape[0] * self.user_item_matrix.shape[1]\n",
    "        sparsity = (1 - num_ratings / total_cells) * 100\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  ‚úÖ Matrix shape: {self.user_item_matrix.shape}\")\n",
    "            print(f\"  ‚úÖ Sparsity: {sparsity:.2f}%\")\n",
    "        \n",
    "        # Calculate item-item similarity\n",
    "        if verbose:\n",
    "            print(\"\\n‚è≥ Computing item-item similarity matrix...\")\n",
    "        \n",
    "        item_similarity = cosine_similarity(self.user_item_matrix.T)\n",
    "        \n",
    "        self.item_similarity_df = pd.DataFrame(\n",
    "            item_similarity,\n",
    "            index=self.user_item_matrix.columns,\n",
    "            columns=self.user_item_matrix.columns\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  ‚úÖ Similarity matrix: {self.item_similarity_df.shape}\")\n",
    "            print(f\"  ‚úÖ Memory usage: {self.item_similarity_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "        \n",
    "        # Update training info\n",
    "        self.training_info = {\n",
    "            'trained_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'num_users': self.user_item_matrix.shape[0],\n",
    "            'num_movies': self.user_item_matrix.shape[1],\n",
    "            'num_ratings': len(ratings_df),\n",
    "            'sparsity': sparsity,\n",
    "            'avg_rating': float(ratings_df['rating'].mean()),\n",
    "            'model_version': '1.0',\n",
    "            'algorithm': 'Item-Based Collaborative Filtering',\n",
    "            'similarity_metric': 'Cosine Similarity'\n",
    "        }\n",
    "        \n",
    "        self.is_trained = True\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "        return self.training_info\n",
    "    \n",
    "    def recommend(self, user_ratings, n_recommendations=10, min_similarity=0.0):\n",
    "        \"\"\"\n",
    "        Generate movie recommendations for a user\n",
    "        \n",
    "        Args:\n",
    "            user_ratings (dict): Dictionary of {movieId: rating}\n",
    "            n_recommendations (int): Number of recommendations to return\n",
    "            min_similarity (float): Minimum similarity threshold (0-1)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Recommended movies with scores, titles, and genres\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise Exception(\"‚ùå Model not trained! Call train() first.\")\n",
    "        \n",
    "        if not user_ratings:\n",
    "            raise ValueError(\"‚ùå user_ratings cannot be empty\")\n",
    "        \n",
    "        # Calculate scores for all movies\n",
    "        scores = {}\n",
    "        \n",
    "        for movie_id, rating in user_ratings.items():\n",
    "            # Skip if movie not in our similarity matrix\n",
    "            if movie_id not in self.item_similarity_df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Get similarities for this movie\n",
    "            similar_movies = self.item_similarity_df[movie_id]\n",
    "            \n",
    "            # Calculate weighted scores\n",
    "            for other_movie_id, similarity in similar_movies.items():\n",
    "                # Skip already rated movies\n",
    "                if other_movie_id in user_ratings:\n",
    "                    continue\n",
    "                \n",
    "                # Apply similarity threshold\n",
    "                if similarity <= min_similarity:\n",
    "                    continue\n",
    "                \n",
    "                # Accumulate weighted score\n",
    "                if other_movie_id not in scores:\n",
    "                    scores[other_movie_id] = 0\n",
    "                scores[other_movie_id] += similarity * rating\n",
    "        \n",
    "        # Handle case where no recommendations can be generated\n",
    "        if not scores:\n",
    "            return pd.DataFrame(columns=['movieId', 'title', 'genres', 'score'])\n",
    "        \n",
    "        # Get top N recommendations\n",
    "        top_movies = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]\n",
    "        recommended_ids = [movie_id for movie_id, score in top_movies]\n",
    "        \n",
    "        # Get movie details\n",
    "        recommendations = self.movies_df[self.movies_df['movieId'].isin(recommended_ids)].copy()\n",
    "        \n",
    "        # Add scores\n",
    "        score_dict = dict(top_movies)\n",
    "        recommendations['score'] = recommendations['movieId'].map(score_dict)\n",
    "        \n",
    "        # Sort by score\n",
    "        recommendations = recommendations.sort_values('score', ascending=False)\n",
    "        \n",
    "        return recommendations[['movieId', 'title', 'genres', 'score']].reset_index(drop=True)\n",
    "    \n",
    "    def get_similar_movies(self, movie_id, n_similar=10, min_similarity=0.3):\n",
    "        \"\"\"\n",
    "        Find movies similar to a given movie\n",
    "        \n",
    "        Args:\n",
    "            movie_id (int): Movie ID to find similar movies for\n",
    "            n_similar (int): Number of similar movies to return\n",
    "            min_similarity (float): Minimum similarity threshold\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Similar movies with similarity scores\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise Exception(\"‚ùå Model not trained! Call train() first.\")\n",
    "        \n",
    "        if movie_id not in self.item_similarity_df.columns:\n",
    "            raise ValueError(f\"‚ùå Movie ID {movie_id} not found in training data\")\n",
    "        \n",
    "        # Get similarities for this movie\n",
    "        similarities = self.item_similarity_df[movie_id]\n",
    "        \n",
    "        # Filter by threshold and exclude self\n",
    "        similar = similarities[similarities >= min_similarity].sort_values(ascending=False)[1:n_similar+1]\n",
    "        \n",
    "        # Get movie details\n",
    "        similar_movies = self.movies_df[self.movies_df['movieId'].isin(similar.index)].copy()\n",
    "        similar_movies['similarity'] = similar_movies['movieId'].map(similar)\n",
    "        similar_movies = similar_movies.sort_values('similarity', ascending=False)\n",
    "        \n",
    "        return similar_movies[['movieId', 'title', 'genres', 'similarity']].reset_index(drop=True)\n",
    "    \n",
    "    def get_info(self):\n",
    "        \"\"\"Get model information and statistics\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return {\"status\": \"Model not trained\"}\n",
    "        \n",
    "        return self.training_info\n",
    "    \n",
    "    def save(self, filepath='models/recommender_model.pkl'):\n",
    "        \"\"\"\n",
    "        Save the trained model to disk\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): Path where to save the model\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise Exception(\"‚ùå Cannot save untrained model!\")\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        # Prepare model data\n",
    "        model_data = {\n",
    "            'user_item_matrix': self.user_item_matrix,\n",
    "            'item_similarity_df': self.item_similarity_df,\n",
    "            'movies_df': self.movies_df,\n",
    "            'training_info': self.training_info\n",
    "        }\n",
    "        \n",
    "        # Save to file\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        \n",
    "        file_size = os.path.getsize(filepath) / 1024**2\n",
    "        print(f\"‚úÖ Model saved to: {filepath}\")\n",
    "        print(f\"üì¶ File size: {file_size:.2f} MB\")\n",
    "        \n",
    "        return filepath\n",
    "    \n",
    "    def load(self, filepath='models/recommender_model.pkl'):\n",
    "        \"\"\"\n",
    "        Load a trained model from disk\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): Path to the saved model\n",
    "        \"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"‚ùå Model file not found: {filepath}\")\n",
    "        \n",
    "        # Load model data\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        # Restore model state\n",
    "        self.user_item_matrix = model_data['user_item_matrix']\n",
    "        self.item_similarity_df = model_data['item_similarity_df']\n",
    "        self.movies_df = model_data['movies_df']\n",
    "        self.training_info = model_data['training_info']\n",
    "        self.is_trained = True\n",
    "        \n",
    "        file_size = os.path.getsize(filepath) / 1024**2\n",
    "        print(f\"‚úÖ Model loaded from: {filepath}\")\n",
    "        print(f\"üì¶ File size: {file_size:.2f} MB\")\n",
    "        print(f\"üìä Model info: {self.training_info['num_movies']} movies, {self.training_info['num_users']} users\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "print(\"‚úÖ MovieRecommender class created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T21:41:06.033123Z",
     "iopub.status.busy": "2025-11-29T21:41:06.032698Z",
     "iopub.status.idle": "2025-11-29T21:41:06.054430Z",
     "shell.execute_reply": "2025-11-29T21:41:06.053032Z",
     "shell.execute_reply.started": "2025-11-29T21:41:06.033082Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING TRAINING DATA\n",
      "================================================================================\n",
      "‚úÖ Loaded from pickle files\n",
      "\n",
      "üìä Dataset summary:\n",
      "  ‚Ä¢ Ratings: 100,000 rows\n",
      "  ‚Ä¢ Movies: 10,329 rows\n",
      "  ‚Ä¢ Users: 668\n",
      "  ‚Ä¢ Movies rated: 10,283\n"
     ]
    }
   ],
   "source": [
    "# Load data from previous notebook\n",
    "print(\"=\" * 80)\n",
    "print(\"LOADING TRAINING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Try to load from pickle (faster), fallback to CSV\n",
    "try:\n",
    "    ratings_df = pd.read_pickle('../../data/ratings_sample.pkl')\n",
    "    movies_df = pd.read_pickle('../../data/movies_sample.pkl')\n",
    "    print(\"‚úÖ Loaded from pickle files\")\n",
    "except:\n",
    "    try:\n",
    "        ratings_df = pd.read_csv('../../data/ratings_sample.csv')\n",
    "        movies_df = pd.read_csv('../../data/movies_sample.csv')\n",
    "        print(\"‚úÖ Loaded from CSV files\")\n",
    "    except:\n",
    "        print(\"‚ùå Data files not found! Please run notebook 01 first.\")\n",
    "        raise\n",
    "\n",
    "print(f\"\\nüìä Dataset summary:\")\n",
    "print(f\"  ‚Ä¢ Ratings: {len(ratings_df):,} rows\")\n",
    "print(f\"  ‚Ä¢ Movies: {len(movies_df):,} rows\")\n",
    "print(f\"  ‚Ä¢ Users: {ratings_df['userId'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Movies rated: {ratings_df['movieId'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T21:41:23.080128Z",
     "iopub.status.busy": "2025-11-29T21:41:23.079740Z",
     "iopub.status.idle": "2025-11-29T21:41:27.249708Z",
     "shell.execute_reply": "2025-11-29T21:41:27.247690Z",
     "shell.execute_reply.started": "2025-11-29T21:41:23.080096Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INITIALIZING AND TRAINING MODEL\n",
      "================================================================================\n",
      "üé¨ MovieRecommender initialized\n",
      "================================================================================\n",
      "TRAINING MOVIE RECOMMENDER\n",
      "================================================================================\n",
      "\n",
      "üìä Training data:\n",
      "  ‚Ä¢ Users: 668\n",
      "  ‚Ä¢ Movies: 10,283\n",
      "  ‚Ä¢ Ratings: 100,000\n",
      "  ‚Ä¢ Average rating: 3.44\n",
      "\n",
      "‚è≥ Creating user-item matrix...\n",
      "  ‚úÖ Matrix shape: (668, 10283)\n",
      "  ‚úÖ Sparsity: 98.54%\n",
      "\n",
      "‚è≥ Computing item-item similarity matrix...\n",
      "  ‚úÖ Similarity matrix: (10283, 10283)\n",
      "  ‚úÖ Memory usage: 807.07 MB\n",
      "\n",
      "================================================================================\n",
      "‚úÖ TRAINING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "üìä Training Statistics:\n",
      "  ‚Ä¢ trained_at: 2025-11-29 21:41:27\n",
      "  ‚Ä¢ num_users: 668\n",
      "  ‚Ä¢ num_movies: 10283\n",
      "  ‚Ä¢ num_ratings: 100000\n",
      "  ‚Ä¢ sparsity: 98.54419334044155\n",
      "  ‚Ä¢ avg_rating: 3.437665\n",
      "  ‚Ä¢ model_version: 1.0\n",
      "  ‚Ä¢ algorithm: Item-Based Collaborative Filtering\n",
      "  ‚Ä¢ similarity_metric: Cosine Similarity\n"
     ]
    }
   ],
   "source": [
    "# Create and train the recommender\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INITIALIZING AND TRAINING MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize recommender\n",
    "recommender = MovieRecommender()\n",
    "\n",
    "# Train the model\n",
    "training_stats = recommender.train(ratings_df, movies_df, verbose=True)\n",
    "\n",
    "# Display training statistics\n",
    "print(\"\\nüìä Training Statistics:\")\n",
    "for key, value in training_stats.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T21:41:42.731088Z",
     "iopub.status.busy": "2025-11-29T21:41:42.730614Z",
     "iopub.status.idle": "2025-11-29T21:41:42.933052Z",
     "shell.execute_reply": "2025-11-29T21:41:42.931353Z",
     "shell.execute_reply.started": "2025-11-29T21:41:42.731049Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING THE TRAINED MODEL\n",
      "================================================================================\n",
      "\n",
      "üß™ TEST 1: User who likes action movies\n",
      "--------------------------------------------------------------------------------\n",
      "User's ratings:\n",
      "  ‚Ä¢ Toy Story (1995): 5.0 ‚≠ê\n",
      "  ‚Ä¢ Jumanji (1995): 4.5 ‚≠ê\n",
      "  ‚Ä¢ Usual Suspects, The (1995): 4.0 ‚≠ê\n",
      "\n",
      "üé¨ Top 5 Recommendations:\n",
      "  1. Jurassic Park (1993)\n",
      "     Score: 6.842 | Genres: Action|Adventure|Sci-Fi|Thriller\n",
      "  2. Pulp Fiction (1994)\n",
      "     Score: 6.621 | Genres: Comedy|Crime|Drama|Thriller\n",
      "  3. Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "     Score: 6.438 | Genres: Action|Adventure\n",
      "  4. Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "     Score: 6.420 | Genres: Action|Adventure|Sci-Fi\n",
      "  5. Star Wars: Episode IV - A New Hope (1977)\n",
      "     Score: 6.385 | Genres: Action|Adventure|Sci-Fi\n",
      "\n",
      "\n",
      "üß™ TEST 2: Find movies similar to a specific movie\n",
      "--------------------------------------------------------------------------------\n",
      "Base movie: Under Siege 2: Dark Territory (1995)\n",
      "Genres: Action\n",
      "\n",
      "üé¨ Similar movies:\n",
      "  1. Specialist, The (1994)\n",
      "     Similarity: 0.543 | Genres: Action|Drama|Thriller\n",
      "  2. Demolition Man (1993)\n",
      "     Similarity: 0.521 | Genres: Action|Adventure|Sci-Fi\n",
      "  3. Striking Distance (1993)\n",
      "     Similarity: 0.501 | Genres: Action|Crime\n",
      "  4. Drop Zone (1994)\n",
      "     Similarity: 0.489 | Genres: Action|Thriller\n",
      "  5. Judge Dredd (1995)\n",
      "     Similarity: 0.443 | Genres: Action|Crime|Sci-Fi\n",
      "\n",
      "\n",
      "üß™ TEST 3: Progressive recommendations (New user journey)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üë§ Step 1: User rates first movie\n",
      "Recommendations after 1 rating:\n",
      "  ‚Ä¢ Star Wars: Episode VI - Return of the Jedi (1983) (Score: 2.96)\n",
      "  ‚Ä¢ Star Wars: Episode IV - A New Hope (1977) (Score: 2.93)\n",
      "  ‚Ä¢ Independence Day (a.k.a. ID4) (1996) (Score: 2.86)\n",
      "\n",
      "üë§ Step 2: User rates 3 more movies\n",
      "Recommendations after 4 ratings:\n",
      "  ‚Ä¢ Jurassic Park (1993) (Score: 7.31)\n",
      "  ‚Ä¢ Pulp Fiction (1994) (Score: 7.15)\n",
      "  ‚Ä¢ Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981) (Score: 6.99)\n",
      "\n",
      "üë§ Step 3: User rates 5 more movies\n",
      "Recommendations after 9 ratings:\n",
      "  ‚Ä¢ Jurassic Park (1993) (Score: 13.72)\n",
      "  ‚Ä¢ Batman (1989) (Score: 13.45)\n",
      "  ‚Ä¢ Speed (1994) (Score: 13.18)\n",
      "\n",
      "‚úÖ All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test the trained model with various scenarios\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TESTING THE TRAINED MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test 1: Simple user profile\n",
    "print(\"\\nüß™ TEST 1: User who likes action movies\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "test_profile_1 = {\n",
    "    1: 5.0,    # Example movie\n",
    "    2: 4.5,    # Example movie\n",
    "    50: 4.0    # Example movie\n",
    "}\n",
    "\n",
    "print(\"User's ratings:\")\n",
    "for movie_id, rating in test_profile_1.items():\n",
    "    movie_info = movies_df[movies_df['movieId'] == movie_id]\n",
    "    if not movie_info.empty:\n",
    "        print(f\"  ‚Ä¢ {movie_info['title'].values[0]}: {rating} ‚≠ê\")\n",
    "\n",
    "recs_1 = recommender.recommend(test_profile_1, n_recommendations=5)\n",
    "print(\"\\nüé¨ Top 5 Recommendations:\")\n",
    "for idx, row in recs_1.iterrows():\n",
    "    print(f\"  {idx+1}. {row['title']}\")\n",
    "    print(f\"     Score: {row['score']:.3f} | Genres: {row['genres']}\")\n",
    "\n",
    "# Test 2: Find similar movies\n",
    "print(\"\\n\\nüß™ TEST 2: Find movies similar to a specific movie\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "sample_movie_id = ratings_df['movieId'].iloc[0]\n",
    "sample_movie = movies_df[movies_df['movieId'] == sample_movie_id]\n",
    "\n",
    "if not sample_movie.empty:\n",
    "    print(f\"Base movie: {sample_movie['title'].values[0]}\")\n",
    "    print(f\"Genres: {sample_movie['genres'].values[0]}\")\n",
    "    \n",
    "    similar = recommender.get_similar_movies(sample_movie_id, n_similar=5)\n",
    "    print(\"\\nüé¨ Similar movies:\")\n",
    "    for idx, row in similar.iterrows():\n",
    "        print(f\"  {idx+1}. {row['title']}\")\n",
    "        print(f\"     Similarity: {row['similarity']:.3f} | Genres: {row['genres']}\")\n",
    "\n",
    "# Test 3: Progressive recommendations (simulating new user)\n",
    "print(\"\\n\\nüß™ TEST 3: Progressive recommendations (New user journey)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nüë§ Step 1: User rates first movie\")\n",
    "progressive_ratings = {1: 5.0}\n",
    "recs = recommender.recommend(progressive_ratings, n_recommendations=3)\n",
    "print(\"Recommendations after 1 rating:\")\n",
    "for idx, row in recs.iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['title']} (Score: {row['score']:.2f})\")\n",
    "\n",
    "print(\"\\nüë§ Step 2: User rates 3 more movies\")\n",
    "progressive_ratings.update({2: 4.0, 50: 4.5, 100: 3.5})\n",
    "recs = recommender.recommend(progressive_ratings, n_recommendations=3)\n",
    "print(\"Recommendations after 4 ratings:\")\n",
    "for idx, row in recs.iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['title']} (Score: {row['score']:.2f})\")\n",
    "\n",
    "print(\"\\nüë§ Step 3: User rates 5 more movies\")\n",
    "progressive_ratings.update({150: 5.0, 200: 4.0, 250: 4.5, 300: 3.0, 350: 4.0})\n",
    "recs = recommender.recommend(progressive_ratings, n_recommendations=3)\n",
    "print(\"Recommendations after 9 ratings:\")\n",
    "for idx, row in recs.iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['title']} (Score: {row['score']:.2f})\")\n",
    "\n",
    "print(\"\\n‚úÖ All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T21:41:52.691487Z",
     "iopub.status.busy": "2025-11-29T21:41:52.691064Z",
     "iopub.status.idle": "2025-11-29T21:41:53.554736Z",
     "shell.execute_reply": "2025-11-29T21:41:53.553488Z",
     "shell.execute_reply.started": "2025-11-29T21:41:52.691450Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL INFORMATION\n",
      "================================================================================\n",
      "\n",
      "üìã Model Details:\n",
      "  ‚Ä¢ trained_at: 2025-11-29 21:41:27\n",
      "  ‚Ä¢ num_users: 668\n",
      "  ‚Ä¢ num_movies: 10283\n",
      "  ‚Ä¢ num_ratings: 100000\n",
      "  ‚Ä¢ sparsity: 98.54419334044155\n",
      "  ‚Ä¢ avg_rating: 3.437665\n",
      "  ‚Ä¢ model_version: 1.0\n",
      "  ‚Ä¢ algorithm: Item-Based Collaborative Filtering\n",
      "  ‚Ä¢ similarity_metric: Cosine Similarity\n",
      "\n",
      "üíæ Model Memory Usage:\n",
      "  ‚Ä¢ User-Item Matrix: 52.41 MB\n",
      "  ‚Ä¢ Item Similarity Matrix: 807.07 MB\n",
      "  ‚Ä¢ Movies DataFrame: 1.62 MB\n",
      "  ‚Ä¢ Total: 861.11 MB\n"
     ]
    }
   ],
   "source": [
    "# Display model information\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_info = recommender.get_info()\n",
    "\n",
    "print(\"\\nüìã Model Details:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüíæ Model Memory Usage:\")\n",
    "print(f\"  ‚Ä¢ User-Item Matrix: {recommender.user_item_matrix.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"  ‚Ä¢ Item Similarity Matrix: {recommender.item_similarity_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"  ‚Ä¢ Movies DataFrame: {recommender.movies_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "total_memory = (\n",
    "    recommender.user_item_matrix.memory_usage(deep=True).sum() +\n",
    "    recommender.item_similarity_df.memory_usage(deep=True).sum() +\n",
    "    recommender.movies_df.memory_usage(deep=True).sum()\n",
    ") / 1024**2\n",
    "\n",
    "print(f\"  ‚Ä¢ Total: {total_memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T21:42:09.483127Z",
     "iopub.status.busy": "2025-11-29T21:42:09.482591Z",
     "iopub.status.idle": "2025-11-29T21:42:09.491204Z",
     "shell.execute_reply": "2025-11-29T21:42:09.489698Z",
     "shell.execute_reply.started": "2025-11-29T21:42:09.483082Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING MODEL\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è  Full model NOT saved (file would be too large)\n",
      "üí° The model can be recreated by running this notebook\n",
      "üí° For deployment, we'll save to Cloud Storage instead\n",
      "\n",
      "üì¶ What's saved:\n",
      "  ‚úÖ Notebook code (can regenerate model)\n",
      "  ‚úÖ Training pipeline (reproducible)\n",
      "  ‚ùå Large model file (excluded from Git)\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "# WARNING: This creates a large file!\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Option 1: Save full model (LARGE FILE - will be excluded from Git)\n",
    "# Uncomment if you want to save locally\n",
    "save_full_model = False  # Set to True to save\n",
    "\n",
    "if save_full_model:\n",
    "    model_path = '../../models/saved_models/movie_recommender_v1.pkl'\n",
    "    recommender.save(model_path)\n",
    "    print(f\"\\n‚úÖ Full model saved to: {model_path}\")\n",
    "    print(\"‚ö†Ô∏è  Note: This file is excluded from Git due to size\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Full model NOT saved (file would be too large)\")\n",
    "    print(\"üí° The model can be recreated by running this notebook\")\n",
    "    print(\"üí° For deployment, we'll save to Cloud Storage instead\")\n",
    "\n",
    "print(\"\\nüì¶ What's saved:\")\n",
    "print(\"  ‚úÖ Notebook code (can regenerate model)\")\n",
    "print(\"  ‚úÖ Training pipeline (reproducible)\")\n",
    "print(\"  ‚ùå Large model file (excluded from Git)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lightweight export for API deployment\n",
    "print(\"=\" * 80)\n",
    "print(\"CREATING LIGHTWEIGHT MODEL EXPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Instead of saving the huge matrices, save only essential info\n",
    "lightweight_export = {\n",
    "    'model_info': recommender.get_info(),\n",
    "    'movies_df': recommender.movies_df,  # Movie metadata is small\n",
    "    'sample_recommendations': {}\n",
    "}\n",
    "\n",
    "# Generate sample recommendations for documentation\n",
    "print(\"\\n‚è≥ Generating sample recommendations...\")\n",
    "sample_users = ratings_df['userId'].sample(5, random_state=42)\n",
    "\n",
    "for user_id in sample_users:\n",
    "    user_ratings_data = ratings_df[ratings_df['userId'] == user_id]\n",
    "    user_profile = dict(zip(\n",
    "        user_ratings_data['movieId'].head(5),\n",
    "        user_ratings_data['rating'].head(5)\n",
    "    ))\n",
    "    \n",
    "    recs = recommender.recommend(user_profile, n_recommendations=5)\n",
    "    lightweight_export['sample_recommendations'][int(user_id)] = recs.to_dict('records')\n",
    "\n",
    "# Save lightweight export\n",
    "os.makedirs('../../models/exports', exist_ok=True)\n",
    "export_path = '../../models/exports/model_info.pkl'\n",
    "\n",
    "with open(export_path, 'wb') as f:\n",
    "    pickle.dump(lightweight_export, f)\n",
    "\n",
    "file_size = os.path.getsize(export_path) / 1024\n",
    "print(f\"\\n‚úÖ Lightweight export saved to: {export_path}\")\n",
    "print(f\"üì¶ File size: {file_size:.2f} KB (much smaller!)\")\n",
    "print(\"\\nüí° This file contains:\")\n",
    "print(\"  ‚Ä¢ Model metadata and statistics\")\n",
    "print(\"  ‚Ä¢ Movie catalog\")\n",
    "print(\"  ‚Ä¢ Sample recommendations for documentation\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
